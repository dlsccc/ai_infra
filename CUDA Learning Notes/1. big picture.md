# GPU
GPU是CPU的协处理器，CPU适合处理逻辑密集型任务（大量条件判断），GPU适合处理计算密集型任务  
# 并行
并行分为指令并行和数据并行  
大规模的数据计算，计算过程较单一，但是数据量庞大，这里聚焦的主要是数据并行。主要分析数据的相关性，哪些可以并行，哪些不可以  
## 数据划分
1. 块划分
  * 一维块划分
  * 二维块划分
2. 周期划分
# 计算机架构
## 按照指令集划分，Flynn's Taxonomy
一种广泛的划分计算机结构的方法Flynn's Taxonomy，根据指令和数据进行CPU的方式，分为四类：  
* SISD 单指令单数据
* SIMD 单指令多数据
* MISD 多指令单数据
* MIMD 多指令多数据

从架构上实现（1）降低延迟、（2）提高带宽、（3）提高吞吐量，来提高并行的计算能力。
* 延迟：指操作从开始到结束的时间，一般微秒级别，延迟越低越好
* 带宽：单位时间内处理的数据量，一般MB/s或者GB/s
* 吞吐量：单位时间内成功处理的运算数量，一般用gflops来表示（十亿次浮点计算）
  
吞吐量和延迟有一定关系，都是反应计算速度的，一个是时间除以运算次数，得到的是单位次数用的时间–延迟，一个是运算次数除以时间，得到的是单位时间执行次数–吞吐量
## 根据内存划分
根据内存划分，可将计算机架构划分为：1. 分布式内存的多节点系统（集群）；2. 共享内存的多处理器系统（多个处理器又可以分为多片处理器和单片多核（众核many-core），GPU就属于众核系统）
# 异构
## 异构架构
什么是异构？不同的计算机架构就是异构  
<插图1>  
CPU和GPU的架构区别：  
* CPU：包含控制单元、缓存、算数逻辑单元（ALU），图中有4个ALU，为四核CPU，DARM是内存，一般是CPU通过总线访问的。
* GPU：一个GPU有很多个SM，每个SM共用一个control单元和cache，同时有很多ALU，所以GPU更适合处理逻辑简单，数据量大的任务。
* CPU和GPU通过PCIe总线连接，传递指令和数据，这部分也是性能的瓶颈之一。

衡量GPU计算能力主要靠两种容量特征：CUDA核心数量（越多越好）；内存大小（越大越好），相应的计算能力的性能指标为：峰值计算能力和内存带宽  
CPU和GPU的线程区别：  
* CPU线程是重量级实体，操作系统交替执行线程，线程上下文切换花销很大
* GPU线程是轻量级的，GPU应用一般包含成千上万的线程，多数在排队状态，线程之间切换基本没有开销
* CPU的核被设计用来尽可能减少一个或两个线程运行时间的延迟，而GPU核则是大量线程，最大幅度提高吞吐量

# 相关概念深入学习资料
并行相关：pThread、OpenMP  
线程相关：《深入理解计算机系统》
# 参考
https://face2ai.com/CUDA-F-1-0-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%9E%B6%E6%9E%84/
