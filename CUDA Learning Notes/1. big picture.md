# GPU
GPU是CPU的协处理器，CPU适合处理逻辑密集型任务（大量条件判断），GPU适合处理计算密集型任务  
# 并行
并行分为指令并行和数据并行  
大规模的数据计算，计算过程较单一，但是数据量庞大，这里聚焦的主要是数据并行。主要分析数据的相关性，哪些可以并行，哪些不可以  
## 数据划分
1. 块划分
  * 一维块划分
  * 二维块划分
2. 周期划分
# 计算机架构
## 按照指令集划分，Flynn's Taxonomy
一种广泛的划分计算机结构的方法Flynn's Taxonomy，根据指令和数据进行CPU的方式，分为四类：  
* SISD 单指令单数据
* SIMD 单指令多数据
* MISD 多指令单数据
* MIMD 多指令多数据

从架构上实现（1）降低延迟、（2）提高带宽、（3）提高吞吐量，来提高并行的计算能力。
* 延迟：指操作从开始到结束的时间，一般微秒级别，延迟越低越好
* 带宽：单位时间内处理的数据量，一般MB/s或者GB/s
* 吞吐量：单位时间内成功处理的运算数量，一般用gflops来表示（十亿次浮点计算）
  
吞吐量和延迟有一定关系，都是反应计算速度的，一个是时间除以运算次数，得到的是单位次数用的时间–延迟，一个是运算次数除以时间，得到的是单位时间执行次数–吞吐量
## 根据内存划分
根据内存划分，可将计算机架构划分为：1. 分布式内存的多节点系统（集群）；2. 共享内存的多处理器系统（多个处理器又可以分为多片处理器和单片多核（众核many-core），GPU就属于众核系统）
# 异构
## 异构架构
什么是异构？不同的计算机架构就是异构  
<插图1>  
CPU和GPU的架构区别：  
* CPU：包含控制单元、缓存、算数逻辑单元（ALU），图中有4个ALU，为四核CPU，DARM是内存，一般是CPU通过总线访问的。
* GPU：一个GPU有很多个SM（流式多处理器），每个SM共用一个control单元和cache，同时有很多ALU，所以GPU更适合处理逻辑简单，数据量大的任务。
* CPU和GPU通过PCIe总线连接，传递指令和数据，这部分也是性能的瓶颈之一。

衡量GPU计算能力主要靠两种容量特征：CUDA核心数量（越多越好）；内存大小（越大越好），相应的计算能力的性能指标为：峰值计算能力和内存带宽  
CPU和GPU的线程区别：  
* CPU线程是重量级实体，操作系统交替执行线程，线程上下文切换花销很大
* GPU线程是轻量级的，GPU应用一般包含成千上万的线程，多数在排队状态，线程之间切换基本没有开销
* CPU的核被设计用来尽可能减少一个或两个线程运行时间的延迟，而GPU核则是大量线程，最大幅度提高吞吐量

# CUDA
CUDA不是一种编程语言，是一个编程模型，且是异构模型，需要CPU和GPU协同工作。CUDA主要定义了三大抽象：  
1. 执行模型：thread最小执行单元/block线程组/grid一次kernel调用的全部线程  
2. 内存模型：多层内存语义  
3. 同步与通信模型：指定哪些线程可以同步等

CUDA程序包含host程序和device程序，host指代cpu及其内存，device指代gpu及其内存，host和device之间可以通信，典型的CUDA程序执行流程：  
1.分配host内存，进行数据初始化；  
2.分配device内存，从host将数据拷贝到device上；  
3.调用CUDA核函数在device上完成指定运算；  
4.将device运算结果拷贝到host上；  
5.释放device和host上分配的内存  
CUDA通过函数类型限定词区别在host和device上执行的函数，主要有`__global__`,`__device__`,`__host__`三个函数限定词  

从宏观上我们进行CUDA应用开发时，从以下三个层面考虑：  
1. 领域层
  * 分析所要解决问题的数据和函数
3. 逻辑层
  * 关注如何组织并发进程。CUDA对线程层结构进行抽象，以允许控制线程行为
4. 硬件层
  * 理解线程如何映射到机器上

## kernel
kernel是cuda中由cpu调用，在gpu上执行的函数，专门为gpu并行计算的执行代码。由`__global__`修饰。  
>注：由`__device__`修饰的函数虽然在gpu上运行，但是不由cpu调用，不会触发gpu上的大量线程，不是kernel函数。 
`__global__`必须是`void`，因为由cpu调用在gpu执行后，返回值无法直接传回cpu，线程执行的结果先写入gpu内存，cpu再通过`cudaMemcpy`取回。且存在并行性冲突，每个线程都可能有自己的返回值，gpu不能直接把所有返回值直接传回cpu。因此kernel只能通过指针参数或全局/共享内存来输出结果。
 
kernel的线程层次结构。GPU有很多并行的轻量级线程，kernel在device上执行时，实际是启动很多线程。一个kernel所启动的所有线程称为一个网格grid，同一个网格上的线程共享相同的全局内存空间。grid是线程结构的第一个层次，grid分为很多个线程块block，一个线程块中有很多个线程，线程块是第二层次。  
grid和block都是定义为`dim3`类型的变量，采用三维尺寸表示grid和block的大小。  

GPU的一个核心组件是SM（流式多处理器），通常包含CUDA核心、寄存器、共享内存、Warp调度器等。一个kernel被执行时，grid中的block被分配到SM上，一个线程块只可以在一个SM上执行，一个SM可以同时执行多个线程块block，也就是说，block是调度的最小单位。这里grid是逻辑层，SM才是执行的物理层。  
SM采用SIMT架构（Single-Instruction, Multiple-Thread 单指令多线程架构），基本执行单元是线程束(Warps)，一个线程束包含32个线程，这些线程执行相同的指令，但是每个线程有自己的指令地址计数器和寄存器状态，也有自己独立的执行路径。一个block被分配到SM上后，会被拆分成多个warp。  
grid和block只是逻辑划分，一个kernel的所有线程其实在物理层上不一定同时并发，所以kernel的grid和block配置不同，性能会出现差异。另外，因为warp包含32个线程，所有block大小一般是32的倍数。  
# 相关概念深入学习资料
并行相关：pThread、OpenMP  
线程相关：《深入理解计算机系统》
# 参考
[1] https://face2ai.com/CUDA-F-1-0-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%9E%B6%E6%9E%84/  
[2] https://zhuanlan.zhihu.com/p/34587739
